
basic:
  model: base
  vocab_size: 2000
  batch_size: 32
  layers: 2
  heads: 2
  dff: 128
  d_model: 32
  max_pe: 1000
  dropout: 0.1
  epochs: 3
  warmup_steps: 4000
  lr_scale: 1.0

aiayn:
  model: base
  vocab_size: 10000
  layers: 6
  heads: 8
  dff: 2048
  d_model: 512
  max_pe: 1500
  dropout: 0.1
  warmup_steps: 4000
  lr_scale: 1.0

small:
  model: base
  vocab_size: 10000
  layers: 1
  heads: 1
  dff: 2048
  d_model: 256
  max_pe: 1500
  dropout: 0.1
  warmup_steps: 4000
  lr_scale: 0.8

